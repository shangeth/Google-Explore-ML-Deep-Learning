{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shangeth/Google-ML-Academy/blob/master/1-Intro-to-Deep-Learning/1_4_2_MultiClass_Classification_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0j5dFed2nzQ"
   },
   "source": [
    "<h1><a href='https://shangeth.com/google-ml-academy/'>Google ML Academy 2019</a></h1>\n",
    "<h3>Instructor: <a href='https://shangeth.com/'>Shangeth Rajaa</a></h3>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJhS9-RC2trS"
   },
   "source": [
    "# Multi Class Classification\n",
    "\n",
    "In the previous notebeook we used logistic regression for Binary Classification, now we will see how to train a classifier model for Multi-Class Classification.\n",
    "\n",
    "**What is Multi-Class Classification?** \n",
    "If the target values have n discrete classification classes ie: y can take discrete value from 0 to n-1. If $y \\in \\{0, 1, 2, 3, ..., n-1\\}$, then the classification task is n-Multi-Class.\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/972/1*SwXHlCzh-d9UqHOglp3vcA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f1PH1I3T7R8Y"
   },
   "source": [
    "# Task - 1 \n",
    "\n",
    "Create a 3-Multi-Class dataset with sklearn.datasets and visualize it.\n",
    "\n",
    "It's very easy, use the same code form previous notebook and make changes for 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xVZ9va7Y5OZs",
    "outputId": "d8eb882f-56ef-4190-ead0-36aa9b08160c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 2), (300,), {0, 1, 2})"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=300, n_features=2, centers=3, random_state=42)\n",
    "\n",
    "X.shape, y.shape, set(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HV8IowwM7wOH"
   },
   "source": [
    "If you made 3 centers, you can see ```set(y)``` will return ```{0, 1, 2}```. where 0 represent the first class, 1 represent second and 2 represents the third class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ksMH7t0S7ndy",
    "outputId": "76f0c9d8-d44c-482d-8b43-f7e00b76ce0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2), (100, 2), (100, 2))"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# getting the index of each class\n",
    "class_0 = np.where(y == 0)\n",
    "class_1 = np.where(y == 1)\n",
    "class_2 = np.where(y == 2)\n",
    "\n",
    "X_0 = X[class_0]\n",
    "X_1 = X[class_1]\n",
    "X_2 = X[class_2]\n",
    "\n",
    "X_0.shape, X_1.shape, X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "C9Jyj7zm8NcZ",
    "outputId": "9c43e33c-1507-4143-fc53-5d515fd7d9f2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuIAAAIjCAYAAABGV34uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.scatter(X_0[:, 0], X_0[:, 1], marker='x', s=150, color='red', label='0')\n",
    "plt.scatter(X_1[:, 0], X_1[:, 1], marker='o', s=150, color='blue', label='1')\n",
    "plt.scatter(X_2[:, 0], X_2[:, 1], marker='s', s=150, color='red', label='2')\n",
    "plt.xlabel('$x1$', fontsize=20)\n",
    "plt.ylabel('$x2$', fontsize=20)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFJ9O1gLBy7y"
   },
   "source": [
    "# How to get the probabilities? : SoftMax\n",
    "\n",
    "Now the target is going to be $y \\in \\{0, 1, 2\\}$, so sigmoid cannot be used here, as sigmoid will convert any number to range 0 to 1 , so it can only be used for binary classification.\n",
    "\n",
    "We need a function which converts the scores/logits of linear mapping into probabilities for all n classes.\n",
    "\n",
    "That function should have some properties:\n",
    "\n",
    "- all probabilities should be >0\n",
    "- probabilities should be in range $[0,1]$\n",
    "- some of all class probabilities = 1\n",
    "\n",
    "<br>\n",
    "One possible function can be class_logit/sum of all class logits. Lets try it\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "$logits = [-100, 40, -10]$, right now don't bother how do we get 3 logits, we will discuss it below.\n",
    "\n",
    "$probabilities = [-100/(-100+40-10), 40/(-100+40-10), -10/(-100+40-10)]$\n",
    "\n",
    "$probabilities = [100/70, -40/70, 10/70]$ \n",
    "\n",
    "you can see this example satisfies only the third property(sum=1). So we need a function which gives positive numbers. Exponential function can help us.\n",
    "\n",
    "$Logits = [l_0, l_1, l_2, ...., l_{n-1}]$\n",
    "\n",
    "$Probabilities = [\\dfrac{e^{l_0}}{e^{l_1} + e^{l_2}+ ... + e^{l_{n-1}}}, \\dfrac{e^{l_1}}{e^{l_1} + e^{l_2}+ ... + e^{l_{n-1}}}, ..., \\dfrac{e^{l_{n-1}}}{e^{l_1} + e^{l_2}+ ... + e^{l_{n-1}}}]$\n",
    "\n",
    "This function is called Softmax, and this gives the probability that a data belongs to class j, given the logits.\n",
    "\n",
    "$P(y=j|z) = \\dfrac{e^{z_j}}{\\sum_{i=0}^{n-1}e^{z_i}}$\n",
    "\n",
    "Let's code softmax function in Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqhcZG0C8f5F"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "  exp = np.exp(x)\n",
    "  exp_sum = exp.sum(axis=1).reshape(-1,1)\n",
    "  return exp/exp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FvOLbFM_SdtE",
    "outputId": "35047b18-f342-4555-c965-373329f7e6fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.52299795e-08, 9.99999985e-01, 9.35762283e-14]])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[22, 40, 10]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fT_IVhgS25P"
   },
   "source": [
    "Now we know, replacing sigmoid with with softmax will help in the case of multi class classification. This softmax model is also called **Softmax Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvUrCWTgUgei"
   },
   "source": [
    "# Loss Function\n",
    "\n",
    "As we have already seen, for classification task we will use Cross Entropy loss.\n",
    "The prediction of softmax regression $\\hat{y} = [0.129, 0.8, 0.071]$, whereas the true label will be one of $y \\in \\{0, 1, 2\\}$. We cannot directly use Cross Entropy loss with $\\hat{y}$ and $y$. \n",
    "\n",
    "So we convert the true label into One-Hot Encoding form. One hot encoding is a vector representation of the label which has '1' at the index corresponding to the label and '0' elsewhere.\n",
    "\n",
    "Example:\n",
    "\n",
    "Let $y \\in \\{0, 1, 2, 3, 4\\}$, then \n",
    "- '4' is represented as $[0, 0, 0, 0, 1]$\n",
    "- '3' is represented as $[0, 0, 0, 1, 0]$\n",
    "- '2' is represented as $[0, 0, 1, 0, 0]$\n",
    "- '1' is represented as $[0, 1, 0, 0, 0]$\n",
    "- '0' is represented as $[1, 0, 0, 0, 0]$\n",
    "\n",
    "Let's code the label to one hot conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "JE0jCm1RSiZN",
    "outputId": "2715c8a9-f363-4f9e-ac24-ee3399588534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_one_hot(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "num_classes = 5\n",
    "labels = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "to_one_hot(labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TVPirthCcSbF"
   },
   "source": [
    "You can also use sklearn.preprocessing.OneHotEncoder to convert labels to one hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "1QDMIWlMZY7u",
    "outputId": "95d239d4-a793-459d-8e20-f47d27277ec1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "labels = np.array([[0], \n",
    "                   [1], \n",
    "                   [2], \n",
    "                   [3], \n",
    "                   [4]])\n",
    "\n",
    "OneHotEncoder(categories='auto').fit_transform(labels).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VeSyPE14fqfS"
   },
   "source": [
    "Keras also have some utils functions which can help in one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "0q4RawnBfwwI",
    "outputId": "d2527ed2-aee1-40a2-ae4e-29f9aff23e8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "labels = np.array([0, 1, 2, 3, 4])\n",
    "to_categorical(labels, num_classes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nGRdPE19m18x"
   },
   "source": [
    "# Softmax Regression Model\n",
    "\n",
    "From what we discussed so far, if the number of classes = 3, then we expect model to give a prediction $\\hat{y} = Softmax(z)$ and $z$ will be like $z = [-10, 20, 5]$(Example).\n",
    "\n",
    "$z = X.W + b$ will only give one number like $z=[4]$ in logistic regression. But now we are using softmax regression which expect a model which gives 3 output for a 3 class classifier. \n",
    "\n",
    "If the no of input features = 2 and no of out[ut classes = 3\n",
    "So we will use 3 linear classifier. \n",
    "\n",
    "$z_1 = X.W_1 + b_1$, $z_2 = X.W_2 + b_2$, $z_3 = X.W_3 + b_3$ which can be combined together with\n",
    "\n",
    "z = $\\begin{bmatrix}z_1&z_2&z_3\\\\ \\end{bmatrix}$ \n",
    "\n",
    "$ z = X . W + b $\n",
    "\n",
    "$W = \\begin{bmatrix}W_1&W_2&W_3\\\\ \\end{bmatrix} $\n",
    "\n",
    "$b = \\begin{bmatrix}b_1&b_2&b_3\\\\ \\end{bmatrix}$\n",
    "\n",
    "each $W_i = \\begin{bmatrix}W_{i1}\\\\W_{i2}\\\\W_{}i3\\\\ \\end{bmatrix} $\n",
    "\n",
    "so the final $W = \\begin{bmatrix}W_{11}&W_{12}&W_{13}\\\\ W_{21}&W_{22}&W_{23}\\\\ \\end{bmatrix}$\n",
    "\n",
    "<br><hr><br>\n",
    "Let $X = \\begin{bmatrix}x_1&x_2\\\\ \\end{bmatrix}$\n",
    "\n",
    "$z = \\begin{bmatrix}x_1&x_2\\\\ \\end{bmatrix} . \\begin{bmatrix}W_{11}&W_{12}&W_{13}\\\\ W_{21}&W_{22}&W_{23}\\\\ \\end{bmatrix} + \\begin{bmatrix}b_1&b_2&b_3\\\\ \\end{bmatrix}$\n",
    "\n",
    "<br>\n",
    "\n",
    "- For 1 data, $(1,2).(2,3) + (1,3) = (1,3)$\n",
    "- For n data, $(n,2).(2,3) + (1,3) = (n,3)$, b will be added to all n data, this is called broadcasting.\n",
    "\n",
    "<br>\n",
    "Frameworks like Tensorflow, PyTorch will take care of this matrix form of $W$ and $b$ for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ex5CKUYSeat7"
   },
   "source": [
    "# Task-2\n",
    "\n",
    "Train a Softmax Regression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l-ZMyD0RcjXs",
    "outputId": "879b302c-5a8d-4e4c-a736-d850bd041c16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1000,), {0, 1, 2})"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=1000, n_features=2, centers=3, random_state=42)\n",
    "X.shape, y.shape, set(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtHahESle2sD"
   },
   "source": [
    "We need to convert the labels into one hot vectors to train the model. Let's use keras to_categorical function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pnUUTh72exBc",
    "outputId": "153a3c24-4041-4ee2-eeb2-8d7cd3d67319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "\n",
    "y = to_categorical(y, num_classes=3)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPcOfy1ThSxJ"
   },
   "source": [
    "## Train-Validation-Test Split\n",
    "\n",
    "So far we had a dataset and we used it for training and checked the accuracy/loss to see the performance. But its not the right way to check the preformance of a model. Usually any dataset is split into 3 parts namely Train-Validation-Test.\n",
    "\n",
    "### train set\n",
    "This dataset is used to train the model. If the training is good, metrics of this dataset will be always good. Almost 60-70% of dataset is given to training set.\n",
    "\n",
    "### validation set\n",
    "After every epoch(generally) of training, metrics of this dataset is checked to ensure, the model is also performing good on unseen data as much as it performs on the training dataset. If the model performs well on training dataset but not good on validation set, it means the model has a problem called 'Overfitting' whcih we will look in more detail later. Some hyper parameters are adjusted to make the model perform well in validation set as well during training. 10-20% of data is given to validation set.\n",
    "\n",
    "### testing set\n",
    "After the training is over for n epochs, when the model performs good in both training and validation sets, a final check is done to see the performance of the model on new unseen dataset. 20-30% of data is given to Test set.\n",
    "\n",
    "\n",
    "The percentage numbers depends on the total number of data we have access to, which you will understand as you work on more projects.\n",
    "\n",
    "We can split the dataset into train-test using ```sklearn.model_selection.train_test_split```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HKvcrb_ifal6",
    "outputId": "8b537fad-7182-4aa6-b865-819a47da1715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) (1000, 3)\n",
      "(800, 2) (200, 2) (800, 3) (200, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "# test_size is the percent of split 0.2 means 20% of data is for testset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nO3hmN_GlFXw"
   },
   "source": [
    "## Tensorflow Model\n",
    "\n",
    "- Make a Dataset with 2 input features, 3 output classes\n",
    "- one hot encode y\n",
    "- Split Dataset into Train-Validation-Test\n",
    "- Train Model with Validation Dataset, check the [docs](https://keras.io/models/model/) on how to use validation data.\n",
    "- predict X_test with the trained model, refer the docs(model.predict function)\n",
    "- convert the prediction of X_test and y_test from one-hot to labels using np.argmax(pred, axis=1)\n",
    "- use sklearn.metrics.accuracy_score on prediction of X_test and y_test to find the accuracy on Test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "J0wAE4Kdj6f_",
    "outputId": "48a07218-afc0-450c-b823-31ccfb0ebd16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples, validate on 320 samples\n",
      "Epoch 1/30\n",
      "1280/1280 [==============================] - 0s 300us/sample - loss: 5.9285 - acc: 0.3305 - val_loss: 5.8832 - val_acc: 0.3281\n",
      "Epoch 2/30\n",
      "1280/1280 [==============================] - 0s 40us/sample - loss: 5.3884 - acc: 0.3305 - val_loss: 5.3271 - val_acc: 0.3281\n",
      "Epoch 3/30\n",
      "1280/1280 [==============================] - 0s 44us/sample - loss: 4.8527 - acc: 0.3305 - val_loss: 4.7648 - val_acc: 0.3281\n",
      "Epoch 4/30\n",
      "1280/1280 [==============================] - 0s 40us/sample - loss: 4.3171 - acc: 0.3305 - val_loss: 4.2103 - val_acc: 0.3281\n",
      "Epoch 5/30\n",
      "1280/1280 [==============================] - 0s 43us/sample - loss: 3.7869 - acc: 0.3305 - val_loss: 3.6651 - val_acc: 0.3281\n",
      "Epoch 6/30\n",
      "1280/1280 [==============================] - 0s 41us/sample - loss: 3.2611 - acc: 0.3305 - val_loss: 3.1202 - val_acc: 0.3281\n",
      "Epoch 7/30\n",
      "1280/1280 [==============================] - 0s 43us/sample - loss: 2.7437 - acc: 0.3305 - val_loss: 2.5868 - val_acc: 0.3281\n",
      "Epoch 8/30\n",
      "1280/1280 [==============================] - 0s 41us/sample - loss: 2.2430 - acc: 0.3305 - val_loss: 2.0784 - val_acc: 0.3313\n",
      "Epoch 9/30\n",
      "1280/1280 [==============================] - 0s 43us/sample - loss: 1.7770 - acc: 0.3313 - val_loss: 1.6166 - val_acc: 0.3313\n",
      "Epoch 10/30\n",
      "1280/1280 [==============================] - 0s 43us/sample - loss: 1.3713 - acc: 0.3516 - val_loss: 1.2350 - val_acc: 0.3625\n",
      "Epoch 11/30\n",
      "1280/1280 [==============================] - 0s 44us/sample - loss: 1.0508 - acc: 0.4227 - val_loss: 0.9456 - val_acc: 0.4469\n",
      "Epoch 12/30\n",
      "1280/1280 [==============================] - 0s 43us/sample - loss: 0.8163 - acc: 0.5320 - val_loss: 0.7323 - val_acc: 0.5688\n",
      "Epoch 13/30\n",
      "1280/1280 [==============================] - 0s 45us/sample - loss: 0.6455 - acc: 0.6359 - val_loss: 0.5811 - val_acc: 0.6938\n",
      "Epoch 14/30\n",
      "1280/1280 [==============================] - 0s 46us/sample - loss: 0.5206 - acc: 0.7102 - val_loss: 0.4705 - val_acc: 0.7563\n",
      "Epoch 15/30\n",
      "1280/1280 [==============================] - 0s 46us/sample - loss: 0.4269 - acc: 0.7688 - val_loss: 0.3876 - val_acc: 0.8125\n",
      "Epoch 16/30\n",
      "1280/1280 [==============================] - 0s 42us/sample - loss: 0.3556 - acc: 0.8234 - val_loss: 0.3222 - val_acc: 0.8594\n",
      "Epoch 17/30\n",
      "1280/1280 [==============================] - 0s 41us/sample - loss: 0.2994 - acc: 0.8703 - val_loss: 0.2724 - val_acc: 0.8938\n",
      "Epoch 18/30\n",
      "1280/1280 [==============================] - 0s 41us/sample - loss: 0.2553 - acc: 0.9055 - val_loss: 0.2327 - val_acc: 0.9156\n",
      "Epoch 19/30\n",
      "1280/1280 [==============================] - 0s 42us/sample - loss: 0.2200 - acc: 0.9305 - val_loss: 0.2007 - val_acc: 0.9531\n",
      "Epoch 20/30\n",
      "1280/1280 [==============================] - 0s 42us/sample - loss: 0.1914 - acc: 0.9547 - val_loss: 0.1752 - val_acc: 0.9656\n",
      "Epoch 21/30\n",
      "1280/1280 [==============================] - 0s 40us/sample - loss: 0.1684 - acc: 0.9664 - val_loss: 0.1533 - val_acc: 0.9750\n",
      "Epoch 22/30\n",
      "1280/1280 [==============================] - 0s 40us/sample - loss: 0.1488 - acc: 0.9773 - val_loss: 0.1361 - val_acc: 0.9844\n",
      "Epoch 23/30\n",
      "1280/1280 [==============================] - 0s 38us/sample - loss: 0.1328 - acc: 0.9875 - val_loss: 0.1216 - val_acc: 0.9875\n",
      "Epoch 24/30\n",
      "1280/1280 [==============================] - 0s 41us/sample - loss: 0.1193 - acc: 0.9898 - val_loss: 0.1092 - val_acc: 0.9937\n",
      "Epoch 25/30\n",
      "1280/1280 [==============================] - 0s 41us/sample - loss: 0.1078 - acc: 0.9914 - val_loss: 0.0987 - val_acc: 0.9969\n",
      "Epoch 26/30\n",
      "1280/1280 [==============================] - 0s 40us/sample - loss: 0.0980 - acc: 0.9937 - val_loss: 0.0896 - val_acc: 0.9969\n",
      "Epoch 27/30\n",
      "1280/1280 [==============================] - 0s 50us/sample - loss: 0.0894 - acc: 0.9953 - val_loss: 0.0818 - val_acc: 0.9969\n",
      "Epoch 28/30\n",
      "1280/1280 [==============================] - 0s 40us/sample - loss: 0.0820 - acc: 0.9961 - val_loss: 0.0751 - val_acc: 0.9969\n",
      "Epoch 29/30\n",
      "1280/1280 [==============================] - 0s 41us/sample - loss: 0.0755 - acc: 0.9969 - val_loss: 0.0691 - val_acc: 0.9969\n",
      "Epoch 30/30\n",
      "1280/1280 [==============================] - 0s 41us/sample - loss: 0.0699 - acc: 0.9969 - val_loss: 0.0637 - val_acc: 0.9969\n",
      "\n",
      "Test Accuracy =  0.995\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Make the Dataset\n",
    "num_classes = 3\n",
    "num_input_features = 2\n",
    "X, y = make_blobs(n_samples=2000, n_features=num_input_features, centers=num_classes, random_state=42)\n",
    "\n",
    "# to categorical\n",
    "y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "# train-test split\n",
    "# 20% of dataset to testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# train-validation split\n",
    "# 20% of trainset to valset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Sequential([keras.layers.Dense(units=num_classes, input_shape=[num_input_features]), keras.layers.Activation('softmax')])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "tf_history = model.fit(X_train, y_train, epochs=30, verbose=True, validation_data=(X_val, y_val))\n",
    "\n",
    "# Prediction for Test set with trained Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_pred, axis=1), np.argmax(y_test, axis=1))\n",
    "\n",
    "print('\\nTest Accuracy = ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DM7EuoNGx6SG"
   },
   "source": [
    "Train the model with different\n",
    "- no of input features\n",
    "- no of output classes\n",
    "- no of data\n",
    "- split of train-validation-test\n",
    "- epochs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1_4_2_MultiClass_Classification_Solution.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
